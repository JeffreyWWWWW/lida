{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIDA - Automatic Generation of Visualizations and Infographics using Large Language Models\n",
    "\n",
    "LIDA is a library for generating data visualizations and data-faithful infographics. LIDA is grammar agnostic (will work with any programming language and visualization libraries e.g. matplotlib, seaborn, altair, d3 etc) and works with multiple large language model providers (OpenAI, PaLM, Cohere, Huggingface). Details on the components of LIDA are described in the [paper here](https://arxiv.org/abs/2303.02927) and in this tutorial [notebook](notebooks/tutorial.ipynb). See the project page [here](https://microsoft.github.io/lida/) for updates!.\n",
    "\n",
    "\n",
    "\n",
    "## Getting Started | Installation\n",
    "\n",
    "```bash \n",
    "pip install -U lida\n",
    "```\n",
    "\n",
    "If you intend to use lida with local huggingface models, you will need to install the `transformers` library. \n",
    "\n",
    "```bash\n",
    "pip install lida[transformers]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LIDA Python API\n",
    "\n",
    "Lida offers a manager class that exposes core functionality of the LIDA system. This tutorial will show you how to use the manager class to create visualizations based on a dataset.\n",
    "\n",
    "### Multiple LLM Backends\n",
    "LIDA supports multiple LLM backends such as `openai`, `cohere`, `palm`, `huggingface` etc. You can switch between backends by setting the `text_gen` parameter in the `Manager` class. By default, LIDA uses the `openai` backend. For a list of supported models and how to configure them, see the [llmx documentation](https://github.com/victordibia/llmx).\n",
    "\n",
    "```python\n",
    "\n",
    "from lida import llm\n",
    "\n",
    "text_gen = llm(\"openai\") # for openai\n",
    "text_gen = llm(provider=\"openai\", api_type=\"azure\", azure_endpoint=os.environ[\"AZURE_OPENAI_BASE\"], api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],    api_version=\"2023-07-01-preview\") # for azure openai\n",
    "text_gen = llm(\"cohere\") # for cohere\n",
    "text_gen = llm(\"palm\") # for palm\n",
    "text_gen = llm(provider=\"hf\", model=\"uukuguy/speechless-llama2-hermes-orca-platypus-13b\", device_map=\"auto\")\n",
    "\n",
    "lida = Manager(text_gen=text_gen)\n",
    "```\n",
    "\n",
    "Note that you can set your llm keys as follows\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=<your key>\n",
    "export COHERE_API_KEY=<your key>\n",
    "# for PaLM\n",
    "export PALM_SERVICE_ACCOUNT_KEY_FILE=<path to gcp service account key file>\n",
    "export PALM_PROJECT_ID=<your gcp project id>\n",
    "```\n",
    "#### Azure OpenAI\n",
    "```python\n",
    "from llmx import  llm, TextGenerationConfig\n",
    "import os \n",
    "\n",
    "text_gen = llm(\n",
    "    provider=\"openai\",\n",
    "    api_type=\"azure\",\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_BASE\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=\"2023-07-01-preview\",\n",
    ")\n",
    "lida = Manager(text_gen=text_gen)\n",
    "```\n",
    "\n",
    "\n",
    "### Summarization Methods \n",
    "The summarizer module works takes an `summary_method` argument which determines if the base summary is enriched by an LLM. By default, the `summary_method` argument is set to `default` for a base summary (statistics etc). Set it to `llm` to enrich/annotate the base summary with an llm.\n",
    "\n",
    "### Caching \n",
    "Each manager method takes a [`textgen_config`](https://github.com/victordibia/llmx/blob/7c0fc093d1b8780ebebc7e080f5c63991514038b/llmx/datamodel.py#L22C10-L22C10) argument which is a dictionary that can be used to configure the text generation process (with parameters for model, temperature, max_tokens, topk etc). One of the keys in this dictionary is `use_cache`. If set to `True`, the manager will cache the generated text associated with that method. Use for speedup and to avoid hitting API limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U lida \n",
    "# !pip install lida[infographics] # for infographics support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lida import Manager, TextGenerationConfig , llm  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Data, Generate Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read file: data\\THL实时数据POC - In Queue Per Minute.xlsx. Error: read_excel() got an unexpected keyword argument 'encoding'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_excel() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m lida \u001b[38;5;241m=\u001b[39m Manager(text_gen \u001b[38;5;241m=\u001b[39m llm(\n\u001b[0;32m     11\u001b[0m     provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     api_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://jeffrey-openai-eastus.openai.azure.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m26c454a33fca450894ad90cd6374c52d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-02-01\u001b[39m\u001b[38;5;124m\"\u001b[39m,)) \u001b[38;5;66;03m# !! api key\u001b[39;00m\n\u001b[0;32m     16\u001b[0m textgen_config \u001b[38;5;241m=\u001b[39m TextGenerationConfig(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 18\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mlida\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTHL实时数据POC - In Queue Per Minute.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextgen_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtextgen_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n\u001b[0;32m     20\u001b[0m goals \u001b[38;5;241m=\u001b[39m lida\u001b[38;5;241m.\u001b[39mgoals(summary, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, textgen_config\u001b[38;5;241m=\u001b[39mtextgen_config)\n",
      "File \u001b[1;32m~\\OneDrive - Avanade\\Jeffrey\\GitHub\\lida\\lida\\components\\manager.py:128\u001b[0m, in \u001b[0;36mManager.summarize\u001b[1;34m(self, data, file_name, n_samples, summary_method, textgen_config)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    127\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 128\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarizer\u001b[38;5;241m.\u001b[39msummarize(\n\u001b[0;32m    132\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, text_gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_gen, file_name\u001b[38;5;241m=\u001b[39mfile_name, n_samples\u001b[38;5;241m=\u001b[39mn_samples,\n\u001b[0;32m    133\u001b[0m     summary_method\u001b[38;5;241m=\u001b[39msummary_method, textgen_config\u001b[38;5;241m=\u001b[39mtextgen_config)\n",
      "File \u001b[1;32m~\\OneDrive - Avanade\\Jeffrey\\GitHub\\lida\\lida\\utils.py:70\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(file_location, encoding)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported file type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mread_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     72\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to read file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive - Avanade\\Jeffrey\\GitHub\\lida\\lida\\utils.py:60\u001b[0m, in \u001b[0;36mread_dataframe.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mRead a dataframe from a given file location and clean its column names.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mIt also samples down to 4500 rows if the data exceeds that limit.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m:return: A cleaned DataFrame.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m file_extension \u001b[38;5;241m=\u001b[39m file_location\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     56\u001b[0m read_funcs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: pd\u001b[38;5;241m.\u001b[39mread_json(file_location, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding),\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: pd\u001b[38;5;241m.\u001b[39mread_csv(file_location, encoding\u001b[38;5;241m=\u001b[39mencoding),\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: pd\u001b[38;5;241m.\u001b[39mread_excel(file_location, encoding\u001b[38;5;241m=\u001b[39mencoding),\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlsx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_parquet,\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeather\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_feather,\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: pd\u001b[38;5;241m.\u001b[39mread_csv(file_location, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m     64\u001b[0m }\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_extension \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m read_funcs:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported file type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: read_excel() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "# lida = Manager(text_gen = llm(\"openai\", api_key=None)) # !! api key\n",
    "# textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"gpt-3.5-turbo-0301\", use_cache=True)\n",
    "\n",
    "# summary = lida.summarize(\"https://raw.githubusercontent.com/uwdata/draco/master/data/cars.csv\", summary_method=\"default\", textgen_config=textgen_config)  \n",
    "# goals = lida.goals(summary, n=2, textgen_config=textgen_config)\n",
    "\n",
    "# for goal in goals:\n",
    "#     display(goal)\n",
    "\n",
    "lida = Manager(text_gen = llm(\n",
    "    provider=\"openai\",\n",
    "    api_type=\"azure\",\n",
    "    azure_endpoint=\"https://jeffrey-openai-eastus.openai.azure.com/\",\n",
    "    api_key=\"26c454a33fca450894ad90cd6374c52d\",\n",
    "    api_version=\"2024-02-01\",)) # !! api key\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"gpt4o\", use_cache=True)\n",
    "\n",
    "summary = lida.summarize(\"data\\THL实时数据POC - In Queue Per Minute.xlsx\", summary_method=\"default\", textgen_config=textgen_config)\n",
    "print(summary)\n",
    "goals = lida.goals(summary, n=2, textgen_config=textgen_config)\n",
    "\n",
    "for goal in goals:\n",
    "    display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goals can also be based on a persona \n",
    "persona = \"a mechanic who wants to buy a car that is cheap but has good gas mileage\"\n",
    "personal_goals = lida.goals(summary, n=2, persona=persona, textgen_config=textgen_config)\n",
    "for goal in personal_goals:\n",
    "    display(goal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=goals[i], textgen_config=textgen_config, library=library)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate visualization via a \"user query\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the average price of cars by type?\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config)  \n",
    "charts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VizOps\n",
    "\n",
    "Given that LIDA represents visualizations as code,\n",
    "the VISGENERATOR also implements submodules\n",
    "to perform operations on this representation. \n",
    "\n",
    "This includes \n",
    "- **Natural language based visualization refinement**: Provides a conversational api to iteratively\n",
    "4Execution in a sandbox environment is recommended.\n",
    "refine generated code (e.g., translate chart t hindi\n",
    ". . . zoom in by 50% etc) which can then be executed to generate new visualizations.\n",
    "- **Visualization explanations and accessibility**:\n",
    "Generates natural language explanations (valuable\n",
    "for debugging and sensemaking) as well as accessibility descriptions (valuable for supporting users\n",
    "with visual impairments).\n",
    "\n",
    "- **Visualization code self-evaluation and repair**:\n",
    "Applies an LLM to self-evaluate generated code on\n",
    "multiple dimensions (see section 4.1.2).\n",
    "\n",
    "- **Visualization recommendation**: Given some context (goals, or an existing visualization), recommend additional visualizations to the user (e.g., for\n",
    "comparison, or to provide additional perspectives).\n",
    "\n",
    "\n",
    "\n",
    "## Natural language based visualization refinement \n",
    "\n",
    "Given some code, modify it based on natural language instructions. This yields a new code snippet that can be executed to generate a new visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = charts[0].code\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0, use_cache=True)\n",
    "instructions = [\"make the chart height and width equal\", \"change the color of the chart to red\", \"translate the chart to spanish\"]\n",
    "edited_charts = lida.edit(code=code,  summary=summary, instructions=instructions, library=library, textgen_config=textgen_config)\n",
    "edited_charts[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization explanations and accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = lida.explain(code=code, library=library, textgen_config=textgen_config) \n",
    "for row in explanations[0]:\n",
    "    print(row[\"section\"],\" ** \", row[\"explanation\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization code self-evaluation and repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = lida.evaluate(code=code,  goal=goals[i], textgen_config=textgen_config, library=library)[0] \n",
    "for eval in evaluations:\n",
    "    print(eval[\"dimension\"], \"Score\" ,eval[\"score\"], \"/ 10\")\n",
    "    print(\"\\t\", eval[\"rationale\"][:200])\n",
    "    print(\"\\t**********************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_config = TextGenerationConfig(n=2, temperature=0.2, use_cache=True)\n",
    "recommended_charts =  lida.recommend(code=code, summary=summary, n=2,  textgen_config=textgen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recommended {len(recommended_charts)} charts\")\n",
    "for chart in recommended_charts:\n",
    "    display(chart) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infographics (Beta)\n",
    "\n",
    "- Explores using LIDA to generate infographics from an existing visualization \n",
    "- Uses the `peacasso` package, and loads open source stable diffusion models \n",
    "- You will need to run `pip install lida[infographics]` to install the required dependencies.\n",
    "- Currently work in progress (work being done to post process infographics with chart axis and title overlays from the original visualization, add presets for different infographic styles, and add more stable diffusion models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lida[infographics] \n",
    "# ensure you have a GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infographics = lida.infographics(visualization = edited_charts[0].raster, n=1, style_prompt=\"pastel art, green pearly rain drops, highly detailed, no blur, white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lida.utils import plot_raster\n",
    "plot_raster([edited_charts[0].raster, infographics[\"images\"][0]]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "189101fc34b85ec7417252a331b6b3ef556b71030ac1f6fe00bfbe1409305460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
